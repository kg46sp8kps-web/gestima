"""add_validation_workflow

Revision ID: 933da2e09e7a
Revises: 09d8cd5db466
Create Date: 2026-02-09 11:02:43.011251

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '933da2e09e7a'
down_revision: Union[str, Sequence[str], None] = '09d8cd5db466'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Skip unnamed constraint changes (SQLite limitation)

    with op.batch_alter_table('milling_estimations', schema=None) as batch_op:
        batch_op.add_column(sa.Column('validation_status', sa.String(length=20), nullable=False, server_default='pending'))
        batch_op.add_column(sa.Column('corrected_material_code', sa.String(length=20), nullable=True))
        batch_op.add_column(sa.Column('corrected_bbox_x_mm', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('corrected_bbox_y_mm', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('corrected_bbox_z_mm', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('corrected_part_type', sa.String(length=10), nullable=True))
        batch_op.add_column(sa.Column('correction_notes', sa.String(length=500), nullable=True))
        batch_op.add_column(sa.Column('validated_by_user_id', sa.Integer(), nullable=True))
        batch_op.add_column(sa.Column('validation_date', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('auto_estimated_time_min', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('auto_estimate_date', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('correction_reason', sa.String(length=200), nullable=True))
        batch_op.drop_index(batch_op.f('ix_milling_estimations_filename'))
        batch_op.create_index(batch_op.f('ix_milling_estimations_filename'), ['filename'], unique=True)

    # Skip parts table changes (not related to this migration)

    with op.batch_alter_table('turning_estimations', schema=None) as batch_op:
        batch_op.add_column(sa.Column('validation_status', sa.String(length=20), nullable=False, server_default='pending'))
        batch_op.add_column(sa.Column('corrected_material_code', sa.String(length=20), nullable=True))
        batch_op.add_column(sa.Column('corrected_bbox_x_mm', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('corrected_bbox_y_mm', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('corrected_bbox_z_mm', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('corrected_part_type', sa.String(length=10), nullable=True))
        batch_op.add_column(sa.Column('correction_notes', sa.String(length=500), nullable=True))
        batch_op.add_column(sa.Column('validated_by_user_id', sa.Integer(), nullable=True))
        batch_op.add_column(sa.Column('validation_date', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('auto_estimated_time_min', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('auto_estimate_date', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('correction_reason', sa.String(length=200), nullable=True))
        batch_op.drop_index(batch_op.f('ix_turning_estimations_filename'))
        batch_op.create_index(batch_op.f('ix_turning_estimations_filename'), ['filename'], unique=True)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('turning_estimations', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_turning_estimations_filename'))
        batch_op.create_index(batch_op.f('ix_turning_estimations_filename'), ['filename'], unique=False)
        batch_op.drop_column('correction_reason')
        batch_op.drop_column('auto_estimate_date')
        batch_op.drop_column('auto_estimated_time_min')
        batch_op.drop_column('validation_date')
        batch_op.drop_column('validated_by_user_id')
        batch_op.drop_column('correction_notes')
        batch_op.drop_column('corrected_part_type')
        batch_op.drop_column('corrected_bbox_z_mm')
        batch_op.drop_column('corrected_bbox_y_mm')
        batch_op.drop_column('corrected_bbox_x_mm')
        batch_op.drop_column('corrected_material_code')
        batch_op.drop_column('validation_status')

    with op.batch_alter_table('parts', schema=None) as batch_op:
        batch_op.add_column(sa.Column('stock_length', sa.REAL(), nullable=True))
        batch_op.add_column(sa.Column('stock_height', sa.REAL(), nullable=True))
        batch_op.add_column(sa.Column('stock_wall_thickness', sa.REAL(), nullable=True))
        batch_op.add_column(sa.Column('stock_width', sa.REAL(), nullable=True))
        batch_op.add_column(sa.Column('stock_diameter', sa.REAL(), nullable=True))

    with op.batch_alter_table('milling_estimations', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_milling_estimations_filename'))
        batch_op.create_index(batch_op.f('ix_milling_estimations_filename'), ['filename'], unique=False)
        batch_op.drop_column('correction_reason')
        batch_op.drop_column('auto_estimate_date')
        batch_op.drop_column('auto_estimated_time_min')
        batch_op.drop_column('validation_date')
        batch_op.drop_column('validated_by_user_id')
        batch_op.drop_column('correction_notes')
        batch_op.drop_column('corrected_part_type')
        batch_op.drop_column('corrected_bbox_z_mm')
        batch_op.drop_column('corrected_bbox_y_mm')
        batch_op.drop_column('corrected_bbox_x_mm')
        batch_op.drop_column('corrected_material_code')
        batch_op.drop_column('validation_status')

    with op.batch_alter_table('material_price_categories', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(None, 'material_groups', ['material_group_id'], ['id'])
        batch_op.alter_column('cutting_data_notes',
               existing_type=sa.String(),
               type_=sa.TEXT(),
               existing_nullable=True)

    with op.batch_alter_table('batches', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['frozen_by_id'], ['id'])

    with op.batch_alter_table('batch_sets', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['frozen_by_id'], ['id'])

    # ### end Alembic commands ###
